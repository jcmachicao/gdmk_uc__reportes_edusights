{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jcmachicao/gdmk_uc__reportes_edusights/blob/main/ucont__mprecitivo_train_202503_tensorready.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAi6hmGNzcAC"
      },
      "source": [
        "# Entrenamiento de Red Neuronal Clasificación Binaria PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWpQ6t7bbRtS"
      },
      "source": [
        "## Preparación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9xMS9sEGsR5C"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE2k8nFzusJY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu9K6zbKJkbu",
        "outputId": "c847b7ec-e911-4783-d3ee-173e18d0f114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph5VJmeBl6HL",
        "outputId": "a50b5cfb-f3e7-4b00-dafc-19d01a17144b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPr5bJoHLFMV",
        "outputId": "f566f152-f11e-44b2-f05a-ab24dbe01166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar  6 11:30:00 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = 'drive/My Drive/00 2025_all/2025 Proyectos/2025__Edusights_JCMV/archivos/aplicativo 2024 edusights/edusights_app/'\n",
        "os.listdir(data_path + 'archivos3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TCOsBWNh7M0",
        "outputId": "4aff1ce6-4b99-47a0-8897-989ce7cd53f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['202510_base_al0503.xlsx',\n",
              " '202510_base_al0503.pkl',\n",
              " 'target_df.pkl',\n",
              " 'X_train_tensor.pt',\n",
              " 'X_train_tensor_sample.pt',\n",
              " 'y_train_tensor.pt',\n",
              " 'resultados_df_new.xlsx']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSw1z8plzUsx"
      },
      "source": [
        "## Rerun or Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeP5GlpI8HA0",
        "outputId": "2603f124-efb7-4261-e9e2-eed365078a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-310b68938b7d>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  X_tot = torch.load(data_path + 'archivos3/' + 'X_train_tensor.pt')\n",
            "<ipython-input-20-310b68938b7d>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  y_tot = torch.load(data_path + 'archivos3/' + 'y_train_tensor.pt')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([8020, 149]), torch.Size([8020]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "X_tot = torch.load(data_path + 'archivos3/' + 'X_train_tensor.pt')\n",
        "y_tot = torch.load(data_path + 'archivos3/' + 'y_train_tensor.pt')\n",
        "X_tot.shape, y_tot.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FRAC_TEST = 0.10"
      ],
      "metadata": {
        "id": "KUeyVoHRi3yu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_tot, y_tot, test_size=FRAC_TEST, random_state=None)"
      ],
      "metadata": {
        "id": "CTyxPChg_C2b"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9B23CqiurHq",
        "outputId": "b7da88dc-3266-498e-df79-7985723b109e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([7218, 149])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.max(), X_train.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELluYCGxvuhh",
        "outputId": "cd86bce0-795b-4f44-e787-66e946d5443a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(74.), tensor(0.))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBPej--4OOyt",
        "outputId": "45b5af9f-4d83-4354-9e9d-67443393ff92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000, 13.4400, 31.0000],\n",
              "        [ 0.0000,  0.0000,  1.0000,  ...,  0.0000, 17.4500, 25.0000],\n",
              "        [ 0.0000,  0.0000,  1.0000,  ...,  0.0000, 15.0500, 38.0000],\n",
              "        ...,\n",
              "        [ 0.0000,  1.0000,  0.0000,  ...,  0.0000, 10.8000, 23.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, 14.4700, 24.0000],\n",
              "        [ 0.0000,  0.0000,  1.0000,  ...,  0.0000, 12.0000, 30.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(y_train > 0).sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GwYFC4Xu7U2",
        "outputId": "3862d3d2-9795-4d19-93bd-bcf6ae478051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3864)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(X_train, data_path + 'archivos/X_train.pt')\n",
        "torch.save(y_train, data_path + 'archivos/y_train.pt')\n",
        "torch.save(X_test, data_path + 'archivos/X_test.pt')\n",
        "torch.save(y_test, data_path + 'archivos/y_test.pt')"
      ],
      "metadata": {
        "id": "JnDWjC2T9pRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = X_train.clone().requires_grad_(True).to(device)  # Create a tensor with requires_grad=True\n",
        "X_test_tensor = X_test.clone().requires_grad_(True).to(device)  # Create a tensor with requires_grad=True\n",
        "y_train_tensor = y_train.clone().requires_grad_(True).to(device)  # Create a tensor with requires_grad=True\n",
        "y_test_tensor = y_test.clone().requires_grad_(True).to(device)  # Create a tensor with requires_grad=True"
      ],
      "metadata": {
        "id": "OVeCOUV0_1rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fnmu0KIECClp",
        "outputId": "78e69f5f-e8f1-4e48-cca4-e975da28fc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6817, 149]) torch.Size([6817])\n",
            "torch.Size([1203, 149]) torch.Size([1203])\n",
            "214\n"
          ]
        }
      ],
      "source": [
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(X_train_tensor.shape, y_train_tensor.shape)\n",
        "print(X_test_tensor.shape, y_test_tensor.shape)\n",
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ImprovedNN1(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ImprovedNN1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 32)\n",
        "        self.fc5 = nn.Linear(32, 1)\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.sigmoid(self.fc5(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "_nye5vQ39Fq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationNN3(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ClassificationNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 2)  # Output layer (2 classes)\n",
        "        self.dropout = nn.Dropout(0.05)  # Reduced dropout\n",
        "        self.leaky_relu = nn.LeakyReLU(0.01)  # Consistent activation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.leaky_relu(self.fc4(x))\n",
        "        x = self.fc5(x)  # No activation here (logits for CrossEntropyLoss)\n",
        "        return x\n",
        "\n",
        "# Initialize model\n",
        "input_size = 149  # Ensure this matches your dataset\n",
        "model = ClassificationNN3(input_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "73pj4oUCvLuv",
        "outputId": "3a76bac0-efa4-4a15-bd5d-1260db3b08a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-61e210a6d16f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mClassificationNN3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassificationNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationNN(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(ClassificationNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 32)\n",
        "        self.fc5 = nn.Linear(32, 2)  # Output layer with 2 neurons for 2 classes\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
        "        # Removed sigmoid as we'll use CrossEntropyLoss\n",
        "        # which combines LogSoftmax and NLLLoss\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.leaky_relu(self.bn3(self.fc3(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc4(x))\n",
        "        x = self.fc5(x)  # No sigmoid here\n",
        "        return x"
      ],
      "metadata": {
        "id": "7W7NDhN6jvxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clWh_UNtFtQ6"
      },
      "source": [
        "### Tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MgKFM_nU-FO",
        "outputId": "94efe29a-cc3b-4c9e-fed2-611fc4b82ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de Entrada:  149 Número de Clases de Salida:  2\n"
          ]
        }
      ],
      "source": [
        "input_size = X_train.shape[1]\n",
        "num_classes = len(np.unique(y_tot))\n",
        "print('Tamaño de Entrada: ', input_size, 'Número de Clases de Salida: ', num_classes)\n",
        "#model = ImprovedNN1(input_size).to(device)\n",
        "model = ClassificationNN(input_size=input_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(model.parameters()).device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gI3RceaBKsYl",
        "outputId": "353f4fe1-8475-4645-e1c8-334b9b83ad60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.BCELoss()  # or nn.BCEWithLogitsLoss() if you remove the sigmoid from the model\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "metadata": {
        "id": "M6-SCZvHkXbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "num_classes = len(np.unique(y_tot)) # Get the number of unique classes from y_tot"
      ],
      "metadata": {
        "id": "AhPWEg2fkNK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 3000"
      ],
      "metadata": {
        "id": "r2bLdAg1koua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            '''\n",
        "            outputs = outputs.squeeze()  # Squeeze to remove extra dimensions\n",
        "            loss = criterion(outputs, labels.float())  # Ensure labels are floats\n",
        "            '''\n",
        "            loss = criterion(outputs, labels.long())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "DyXwM7VvtUOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz_Jt6SIFRU7"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_v2(model, test_data, test_labels):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(test_data)\n",
        "\n",
        "    '''\n",
        "    outputs_show = outputs.cpu().numpy().flatten()\n",
        "    outputs_show[outputs_show > 0.51] = 1.0\n",
        "    outputs_show[outputs_show < 0.49] = 0.0\n",
        "    '''\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    outputs_show = predicted.cpu().numpy()\n",
        "    test_labels_np = test_labels.detach().cpu().numpy()\n",
        "\n",
        "    accuracy = 100 * (np.sum(outputs_show == test_labels_np) / len(test_labels_np))\n",
        "    print(f'Precisión del Modelo en Data de Prueba: {accuracy:.2f}%')\n",
        "\n",
        "    results_df = pd.DataFrame({\n",
        "        'Real': test_labels_np,\n",
        "        'Pred': outputs_show\n",
        "    })\n",
        "\n",
        "    return results_df, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Y6on57q5ZIVe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4dB8VEgvESK9",
        "outputId": "43e01e6a-8c75-43b2-c011-86908ab0dfa5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [971/1000], Loss: 0.6998\n",
            "Epoch [972/1000], Loss: 0.7003\n",
            "Epoch [973/1000], Loss: 0.6988\n",
            "Epoch [974/1000], Loss: 0.6987\n",
            "Epoch [975/1000], Loss: 0.7005\n",
            "Epoch [976/1000], Loss: 0.7011\n",
            "Epoch [977/1000], Loss: 0.7013\n",
            "Epoch [978/1000], Loss: 0.6999\n",
            "Epoch [979/1000], Loss: 0.7012\n",
            "Epoch [980/1000], Loss: 0.7010\n",
            "Epoch [981/1000], Loss: 0.7011\n",
            "Epoch [982/1000], Loss: 0.6994\n",
            "Epoch [983/1000], Loss: 0.7006\n",
            "Epoch [984/1000], Loss: 0.7000\n",
            "Epoch [985/1000], Loss: 0.7004\n",
            "Epoch [986/1000], Loss: 0.6998\n",
            "Epoch [987/1000], Loss: 0.7006\n",
            "Epoch [988/1000], Loss: 0.7018\n",
            "Epoch [989/1000], Loss: 0.6990\n",
            "Epoch [990/1000], Loss: 0.7011\n",
            "Epoch [991/1000], Loss: 0.7008\n",
            "Epoch [992/1000], Loss: 0.7001\n",
            "Epoch [993/1000], Loss: 0.6990\n",
            "Epoch [994/1000], Loss: 0.7000\n",
            "Epoch [995/1000], Loss: 0.6987\n",
            "Epoch [996/1000], Loss: 0.6985\n",
            "Epoch [997/1000], Loss: 0.6987\n",
            "Epoch [998/1000], Loss: 0.7015\n",
            "Epoch [999/1000], Loss: 0.6985\n",
            "Epoch [1000/1000], Loss: 0.7011\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the model\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_tensor.shape, y_test_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xQiyuW2q1WT",
        "outputId": "94a86b24-81ed-4854-b0ca-e1d3090f7389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1604, 149]), torch.Size([1604]))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df, accuracy = evaluate_model_v2(model, X_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuZbJ7LNqQsJ",
        "outputId": "aed64385-5fb5-496a-82d4-8bcba94d8bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del Modelo en Data de Prueba: 47.57%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERSION_NAME = 'S3_CON_100'"
      ],
      "metadata": {
        "id": "6swlWOpnrrsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SgWLXkusGnr"
      },
      "outputs": [],
      "source": [
        "results_df.to_excel(data_path + f'results_{VERSION_NAME}.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS2RpVxQ_sUh",
        "outputId": "12133c6b-706a-4e10-dd01-cbeca0114791"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47.56857855361596"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-wM92kc-08w"
      },
      "outputs": [],
      "source": [
        "model_name = f'edusights_20240702_model_{VERSION_NAME}.pth'\n",
        "dict_name = f'edusights_20240702_state_dict_{VERSION_NAME}.pth'\n",
        "torch.save(model, data_path + 'modelos/' + model_name)\n",
        "torch.save(model.state_dict(), data_path + 'modelos/' + dict_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1zfYKY2ZcEv6nqR3E-R2Q-HER7tFI0tPe",
      "authorship_tag": "ABX9TyPIEQz9vJVIBSFujUuDAUxw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}